{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **📄 Document type classification baseline code**\n","> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     \n","> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.\n","\n","## Contents\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Load Data\n","- Train Model\n","- Inference & Save File\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zkH9T_86lDSS"},"source":["## 1. Prepare Environments\n","\n","* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n","* 필요한 라이브러리를 설치합니다."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions\n","* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n","* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["64"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["import multiprocessing\n","\n","num_workers = multiprocessing.cpu_count()  # 시스템의 CPU 코어 수를 가져옴"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9396,"status":"ok","timestamp":1700314592802,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import timm\n","import torch\n","import albumentations as A\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from albumentations.pytorch import ToTensorV2\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","from torch.cuda.amp import GradScaler, autocast\n","\n","# Optuna 임포트\n","import optuna\n","from optuna.integration import PyTorchLightningPruningCallback"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# 시드를 고정합니다.\n","SEED = 2024\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1700314772722,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["# 데이터셋 클래스를 정의합니다.\n","class ImageDataset(Dataset):\n","    def __init__(self, df, path, transform=None):\n","        self.df = df.values\n","        self.path = path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700315066028,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"kTECBJfVTbdl"},"outputs":[],"source":["# one epoch 학습을 위한 함수입니다.\n","def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler):\n","    model.train()\n","    train_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(loader, leave=False)\n","    for image, targets in pbar:\n","        image = image.to(device)\n","        targets = targets.to(device)\n","\n","        optimizer.zero_grad(set_to_none=True)\n","\n","        with autocast():\n","            preds = model(image)\n","            loss = loss_fn(preds, targets)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        train_loss += loss.item()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","\n","        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n","\n","    train_loss /= len(loader)\n","    train_acc = accuracy_score(targets_list, preds_list)\n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"train_loss\": train_loss,\n","        \"train_acc\": train_acc,\n","        \"train_f1\": train_f1,\n","    }\n","\n","    return ret"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# 검증을 위한 함수입니다.\n","def validate(loader, model, loss_fn, device):\n","    model.eval()\n","    val_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    with torch.no_grad():\n","        for image, targets in loader:\n","            image = image.to(device)\n","            targets = targets.to(device)\n","\n","            preds = model(image)\n","            loss = loss_fn(preds, targets)\n","\n","            val_loss += loss.item()\n","            preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n","            targets_list.extend(targets.cpu().numpy())\n","\n","    val_loss /= len(loader)\n","    val_acc = accuracy_score(targets_list, preds_list)\n","    val_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"val_loss\": val_loss,\n","        \"val_acc\": val_acc,\n","        \"val_f1\": val_f1,\n","    }\n","\n","    return ret"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wjom43UvoXcx"},"source":["## 3. Hyper-parameters\n","* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"KByfAeRmXwYk"},"outputs":[],"source":["# device 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 데이터셋 로드\n","data_path = 'data/'\n","train_df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n","tst_df = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n","\n","# 테스트 데이터셋 정의\n","tst_dataset = ImageDataset(\n","    tst_df,\n","    os.path.join(data_path, \"test/\"),\n","    transform=None  # 나중에 설정\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Optuna 목적 함수 정의\n","def objective(trial):\n","    # 하이퍼파라미터 탐색 공간 정의\n","    model_name = trial.suggest_categorical('model_name', ['resnet50', 'efficientnet_b0', 'efficientnet_b3'])\n","    img_size = trial.suggest_categorical('img_size', [224, 256, 299])\n","    batch_size = trial.suggest_categorical('batch_size', [16, 32])\n","    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n","    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n","    epochs = 10  # 하이퍼파라미터 탐색 시에는 에포크 수를 적게 설정\n","\n","    # 데이터 변환 정의\n","    trn_transform = A.Compose([\n","        A.Resize(height=img_size, width=img_size),\n","        A.RandomRotate90(p=0.5),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.ShiftScaleRotate(p=0.5),\n","        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n","        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        ToTensorV2(),\n","    ])\n","\n","    tst_transform = A.Compose([\n","        A.Resize(height=img_size, width=img_size),\n","        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        ToTensorV2(),\n","    ])\n","\n","    # 데이터셋 분할\n","    train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=SEED, stratify=train_df['target'])\n","\n","    # Dataset 정의\n","    trn_dataset = ImageDataset(\n","        train_data,\n","        os.path.join(data_path, \"train/\"),\n","        transform=trn_transform\n","    )\n","    val_dataset = ImageDataset(\n","        val_data,\n","        os.path.join(data_path, \"train/\"),\n","        transform=tst_transform\n","    )\n","\n","    # DataLoader 정의\n","    trn_loader = DataLoader(\n","        trn_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","\n","    # 모델 정의\n","    model = timm.create_model(\n","        model_name,\n","        pretrained=True,\n","        num_classes=17\n","    ).to(device)\n","\n","    # Loss 함수, 옵티마이저, 스케줄러 정의\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n","    scaler = GradScaler()\n","\n","    # 학습 루프\n","    for epoch in range(epochs):\n","        ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device, scaler=scaler)\n","        val_ret = validate(val_loader, model, loss_fn, device=device)\n","        scheduler.step()\n","\n","        # Optuna에 중간 결과 보고\n","        trial.report(val_ret['val_f1'], epoch)\n","\n","        # Pruning 여부 확인\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","    return val_ret['val_f1']  # 최대화할 목표: val_f1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Optuna 스터디 생성 및 최적화\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=20)\n","\n","# 최적의 하이퍼파라미터 출력\n","print('Best trial:')\n","trial = study.best_trial\n","\n","print(f'  Val F1 Score: {trial.value}')\n","print('  Best hyperparameters:')\n","for key, value in trial.params.items():\n","    print(f'    {key}: {value}')\n","\n","# 최적의 하이퍼파라미터로 최종 모델 학습\n","best_params = trial.params\n","\n","# 최적의 하이퍼파라미터 설정\n","model_name = best_params['model_name']\n","img_size = best_params['img_size']\n","batch_size = best_params['batch_size']\n","lr = best_params['lr']\n","weight_decay = best_params['weight_decay']\n","epochs = 30  # 최종 학습 시에는 더 많은 에포크 사용"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"amum-FlIojc6"},"source":["## 4. Load Data\n","* 학습, 테스트 데이터셋과 로더를 정의합니다."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"llh5C7ZKoq2S"},"outputs":[],"source":["# 데이터 변환 재정의\n","trn_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.RandomRotate90(p=0.5),\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    A.ShiftScaleRotate(p=0.5),\n","    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])\n","\n","tst_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 전체 학습 데이터로 재학습\n","trn_dataset = ImageDataset(\n","    train_df,\n","    os.path.join(data_path, \"train/\"),\n","    transform=trn_transform\n",")\n","\n","trn_loader = DataLoader(\n","    trn_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    pin_memory=True,\n","    drop_last=False\n",")\n","\n","tst_dataset.transform = tst_transform"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델 정의\n","model = timm.create_model(\n","    model_name,\n","    pretrained=True,\n","    num_classes=17\n",").to(device)\n","\n","# Loss 함수, 옵티마이저, 스케줄러 정의\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n","scaler = GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 학습 루프\n","for epoch in range(epochs):\n","    ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device, scaler=scaler)\n","    scheduler.step()\n","\n","    # 로그 출력\n","    log = f\"Epoch {epoch+1}/{epochs}\\n\"\n","    for k, v in ret.items():\n","        log += f\"{k}: {v:.4f}  \"\n","    print(log)\n","\n","# 테스트 데이터에 대한 예측\n","tst_loader = DataLoader(\n","    tst_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=num_workers,\n","    pin_memory=True\n",")\n","\n","preds_list = []\n","\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for image, _ in tqdm(tst_loader):\n","    image = image.to(device)\n","\n","    with torch.no_grad():\n","        preds = model(image)\n","    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n","pred_df['target'] = preds_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_submission_df = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n","assert (sample_submission_df['ID'] == pred_df['ID']).all()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_df.to_csv(\"pred.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
